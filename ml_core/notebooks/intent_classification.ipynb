{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c75ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "import re\n",
    "from functools import lru_cache\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn import model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e02f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "695ffcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28486497",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/intent_dataset.csv')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[а-яёЁ]+\")\n",
    "\n",
    "class_map = {\n",
    "    'open': 0,\n",
    "    'write': 1,\n",
    "    'close': 2,\n",
    "    'delete': 3,\n",
    "    'mute': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1171cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['intent'] = data['intent'].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ebd7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c87f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794700b",
   "metadata": {},
   "source": [
    "## logisticreg + tfidf + base preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf6915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, y_train, y_test = model_selection.train_test_split(data.drop('intent', axis=1), data['intent'], \n",
    "                                                                      test_size=0.1,\n",
    "                                                                      random_state=RANDOM_STATE, \n",
    "                                                                      stratify=data['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e6978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 803 ms, sys: 297 µs, total: 804 ms\n",
      "Wall time: 805 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['lemmas'] = train_df['text'].map(clean_text)\n",
    "test_df['lemmas'] = test_df['text'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56bd5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 s, sys: 5.39 s, total: 8.18 s\n",
      "Wall time: 613 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf = vec.fit_transform(train_df['lemmas'])\n",
    "\n",
    "clf = LogisticRegression(random_state=RANDOM_STATE, max_iter=10000)\n",
    "clf.fit(tfidf, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(test_df['lemmas']))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f233141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 654 µs, sys: 3.83 ms, total: 4.49 ms\n",
      "Wall time: 3.86 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = clf.predict(vec.transform(test_df['lemmas']))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "05106306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191                 открыть сообщение друг который жить страна\n",
       "2424                       отключить уведомление выходной день\n",
       "160                                  запустить новый настройка\n",
       "243                                                  запустить\n",
       "1667                         удалить сообщение отметить важный\n",
       "                                 ...                          \n",
       "2545    хотеть получать уведомление активный приложение минута\n",
       "1563                               закрыть подменить настройка\n",
       "2055                           убрать свой сообщение последний\n",
       "1077                                   закрыть диалоговый окно\n",
       "1658          удалить сообщение который отправить определённый\n",
       "Name: lemmas, Length: 256, dtype: object"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a51470fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        55\n",
      "           1       0.98      0.96      0.97        51\n",
      "           2       0.98      1.00      0.99        51\n",
      "           3       0.98      1.00      0.99        53\n",
      "           4       0.98      0.96      0.97        46\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18e78318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 ms, sys: 0 ns, total: 1.6 ms\n",
      "Wall time: 1.67 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "407    открыть страница доставка\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df['text'].sample().map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36730cb0",
   "metadata": {},
   "source": [
    "## logisticreg + Word2Vec(FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65d713d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=list(train_df.lemmas.str.split()), \n",
    "                          vector_size=50, window=5, workers=4, min_count=0).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1bcb9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText(sentences=list(train_df.lemmas.str.split()),\n",
    "                         vector_size=50, window=5, workers=4, min_count=0).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fd3074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(df, model, embed_size=300):\n",
    "    doc_vectors = []\n",
    "    \n",
    "    for doc in tqdm(df.lemmas.str.split()):\n",
    "        res = np.zeros(embed_size)\n",
    "        cnt = 0\n",
    "        for word in doc:\n",
    "            res += model[word]\n",
    "            cnt += 1\n",
    "        if cnt != 0:\n",
    "            res /= cnt\n",
    "        \n",
    "        doc_vectors.append(res)\n",
    "    \n",
    "    return np.array(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3d0a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_w2v(df, model, embed_size=300):\n",
    "    doc_vectors = []\n",
    "    \n",
    "    for doc in tqdm(df.lemmas.str.split()):\n",
    "        res = np.zeros(embed_size)\n",
    "        cnt = 0\n",
    "        for word in doc:\n",
    "            if model.__contains__(word):\n",
    "                res += model[word]\n",
    "                cnt += 1\n",
    "        if cnt != 0:\n",
    "            res /= cnt\n",
    "        doc_vectors.append(res)\n",
    "        \n",
    "    return np.array(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dbbd4079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c1d70a6aa64023872875e10fbf2d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f687d6335f4e088bb72283552f24d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 ms, sys: 1.82 ms, total: 124 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#word2vec\n",
    "train_w2v = get_embeddings_w2v(train_df, word2vec_model, 50)\n",
    "test_w2v = get_embeddings_w2v(test_df, word2vec_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a9d8a0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640625"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pd.DataFrame(train_w2v), y_train)\n",
    "\n",
    "pred = clf.predict(pd.DataFrame(test_w2v))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b2aa799c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4916f4c5f348459cbb5fa95573ab1c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58b16d0b8594073a7e81832d473201d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.6 ms, sys: 12.3 ms, total: 109 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasttext\n",
    "train_fasttext = get_embeddings(train_df, fasttext_model, 50)\n",
    "test_fasttext = get_embeddings(test_df, fasttext_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5548d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34375"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pd.DataFrame(train_fasttext), y_train)\n",
    "\n",
    "pred = clf.predict(pd.DataFrame(test_fasttext))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec069a3f",
   "metadata": {},
   "source": [
    "## logisticreg + Word2Vec(FastText) + TF-IDF(CountVec) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "19beb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tfidf(df, model, embed_size=50):\n",
    "    doc_vectors = []\n",
    "    \n",
    "    for doc in tqdm(df.lemmas.str.split()):\n",
    "        res = np.zeros(embed_size)\n",
    "        cnt = 0\n",
    "        for word in doc:\n",
    "            if model.__contains__(word):\n",
    "                res += tf_idf_voc[word] * model[word]\n",
    "                cnt += 1\n",
    "        if cnt != 0:\n",
    "            res /= cnt\n",
    "        doc_vectors.append(res)\n",
    "    \n",
    "    return doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a78f86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf = vec.fit_transform(train_df['lemmas'])\n",
    "\n",
    "tf_idf_voc = {word: vec.idf_[i] for word, i in vec.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5bac5bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb29cf86a24b9b86e433eadf483e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df766469a804241805ed9fc37b4217d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82 ms, sys: 5.79 ms, total: 87.8 ms\n",
      "Wall time: 85.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasttext\n",
    "train_w2v = w2v_tfidf(train_df, word2vec_model, 50)\n",
    "test_w2v = w2v_tfidf(test_df, word2vec_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "98218561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80078125"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pd.DataFrame(train_w2v), y_train)\n",
    "\n",
    "pred = clf.predict(pd.DataFrame(test_w2v))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ae8c2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестить предобученные не буду\\ нет смысла."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7314f5c",
   "metadata": {},
   "source": [
    "## conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd88e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.vocab import vocab\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "\n",
    "from collections import OrderedDict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30b766d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30\n",
    "embedding_dim = 50\n",
    "num_epochs = 15\n",
    "batch_size = 16\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3ec32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for line in data.itertuples():\n",
    "    tokens = clean_text(line.text).split()\n",
    "    sup_counter = Counter(tokens)\n",
    "    counter.update(sup_counter)\n",
    "    1\n",
    "specials = ['<pad>', '<unk>']\n",
    "for special in specials:\n",
    "    counter[special] = 0\n",
    "    \n",
    "ordered_dict = OrderedDict(sorted(counter.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81bb459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabular = vocab(ordered_dict, min_freq=1, specials=['<pad>', '<unk>'])\n",
    "vocabular.set_default_index(vocabular['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6a9919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1], 1032)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabular.lookup_indices(['<pad>', '<unk>']), len(vocabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "146a5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping\n",
    "sent = list(data.text.map(clean_text).str.split())\n",
    "fasttext_model = FastText(sentences=sent,\n",
    "                         vector_size=50, window=5, workers=4, min_count=0).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "331da520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, vocabular, max_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.vocabular = vocabular\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.texts = []\n",
    "        self.tokens = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for line in df.itertuples():\n",
    "            self.texts.append(line.text)\n",
    "            toks = clean_text(line.text).split()[:max_len]\n",
    "            self.tokens.append([self.vocabular[t] for t in toks])\n",
    "            self.labels.append(line.intent)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        res = {}\n",
    "        \n",
    "        res['text'] = self.texts[idx]\n",
    "        res['labels'] = torch.as_tensor(self.labels[idx], dtype=torch.int64)\n",
    "        res['tokens'] = torch.as_tensor(self.tokens[idx], dtype=torch.int64)\n",
    "        res['tokens_len'] = torch.as_tensor(len(self.tokens[idx]), dtype=torch.int64)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dad2cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, padding_value=0, batch_first=True):\n",
    "    \n",
    "    labels, tokens, tokens_lens = [], [], []\n",
    "    for b in batch:\n",
    "        labels.append(b['labels'])\n",
    "        tokens.append(b['tokens'])\n",
    "        tokens_lens.append(b['tokens_len'])\n",
    "    \n",
    "    res = {}\n",
    "    res['tokens'] = torch.nn.utils.rnn.pad_sequence(tokens, batch_first=batch_first, padding_value=padding_value)\n",
    "    res['tokens_lens'] = torch.stack(tokens_lens)\n",
    "    res['labels'] = torch.stack(labels)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f7347e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(vocabular), embedding_dim=embed_size)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.cl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 2 * hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2 * hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)  # (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, embed_dim, seq_len)\n",
    "        x = self.cnn(x)\n",
    "        prediction = self.cl(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e243f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model, trainloader, validloader, num_epochs, optimizer, loss_func, scheduler,\n",
    "              num_freeze_iter=100, max_grad_norm=1):\n",
    "    \n",
    "    train_losses, valid_losses = [], []\n",
    "    valid_score = []\n",
    "    \n",
    "    last_loss = 100\n",
    "    best_val_loss = 100\n",
    "    patience = 6\n",
    "    trigger_times = 0\n",
    "    \n",
    "    num_iter = 0\n",
    "    \n",
    "    freeze_embedding(model)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        training_bar = tqdm(trainloader, unit='batch')\n",
    "\n",
    "        for batch in training_bar:\n",
    "            \n",
    "            if num_iter > num_freeze_iter:\n",
    "                freeze_embeddings(model, True)\n",
    "            \n",
    "            training_bar.set_description(f'Epoch {epoch + 1}, train stage')\n",
    "            x_batch, y_batch = batch['tokens'].to(device), batch['labels'].to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            loss = loss_func(y_pred, y_batch)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "\n",
    "            training_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        \n",
    "        validation_bar = tqdm(validloader, unit='batch')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_obj = 0\n",
    "            \n",
    "            for batch in validation_bar:\n",
    "                validation_bar.set_description(f'Epoch {epoch + 1}, validation stage')\n",
    "                \n",
    "                x_batch, y_batch = batch['tokens'].to(device), batch['labels'].to(device)\n",
    "                y_pred = model(x_batch)\n",
    "                \n",
    "                loss = loss_func(y_pred, y_batch)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                correct += (y_batch == y_pred.argmax(-1)).float().sum()\n",
    "                num_obj += len(y_batch)\n",
    "                \n",
    "                validation_bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        valid_losses.append(running_loss / len(validloader))\n",
    "        valid_score.append(correct / num_obj)\n",
    "        \n",
    "        ###Early stopping\n",
    "        if valid_losses[-1] > last_loss:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\n')\n",
    "                return model, train_losses, valid_losses, valid_score\n",
    "        else:\n",
    "            trigger_times = 0       \n",
    "        last_loss = valid_losses[-1]\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}... training loss: {train_losses[-1]}, validation loss: {valid_losses[-1]},\\\n",
    "              validation_score: {valid_score[-1]}')\n",
    "        \n",
    "    return model, train_losses, valid_losses, valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68e8cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = model_selection.train_test_split(data, test_size=0.1, \n",
    "                                                     random_state=RANDOM_STATE, \n",
    "                                                     stratify=data['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c30c81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = model_selection.train_test_split(train_df, test_size=0.1,\n",
    "                                                   random_state=RANDOM_STATE,\n",
    "                                                   stratify=train_df['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5eb9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = CustomDataset(train_df, vocabular, max_len)\n",
    "val_df = CustomDataset(val_df, vocabular, max_len)\n",
    "test_df = CustomDataset(test_df, vocabular, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56e8b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_df, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn) \n",
    "validloader = DataLoader(val_df, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "testloader = DataLoader(test_df, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2dbbba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ConvNet(fasttext_model.vector_size, 50).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer, 1e-4, 1e-3, cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ae8cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in vocabular.get_stoi().items():\n",
    "        model.embeddings.weight[idx] = torch.from_numpy(fasttext_model.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4526f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embeddings\n",
    "    for param in embeddings.parameters():\n",
    "        param.requires_grad = req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87db559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2e4d11bcf947ce9452d8bd3d6245b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63df2bb662493b998d9a3bcc7e64bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26d234df5c144e08028507428ac5d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1... training loss: 1.4639740861379182, validation loss: 1.3807529926300048,              validation_score: 0.3982684016227722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066968f3722644bab9ec81b7714049a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa971e8b0bd4de8b1884d465a06efda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2... training loss: 1.3081502648500296, validation loss: 1.1729651967684427,              validation_score: 0.4502164423465729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea39ddca78c4e1fb75409fccd66b57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7cf15c68b54f45b1cf3a30a4dd416f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3... training loss: 1.085155734190574, validation loss: 0.9765977462132772,              validation_score: 0.5281385183334351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec691fd9b324681b8a2f15a6c093749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e453c834d9e040faa45daa550dfcdc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4... training loss: 0.8910312056541443, validation loss: 0.7228906929492951,              validation_score: 0.6320346593856812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d541ac09029456194cca34e9f6be4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089e1bf4958f475a9a4e161ed997f028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5... training loss: 0.681978969849073, validation loss: 0.5207610348860423,              validation_score: 0.7316017150878906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419b0fb3d51e420eb1c0106e0c588dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa457f7c5b7741a0899d7ffd9a1ef4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6... training loss: 0.4703687499348934, validation loss: 0.34068605800469715,              validation_score: 0.7489177584648132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbfd732c97d4e7e80bd5ff4b84bd9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6138b7010de0497b992198e976f6a42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7... training loss: 0.28890938248771886, validation loss: 0.22594904924432438,              validation_score: 0.7575757503509521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280b33d4476047c39bc20df003f4e5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22151a0a010442fcbc7a7059677026cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8... training loss: 0.1803579911016501, validation loss: 0.1561252428839604,              validation_score: 0.7532467246055603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b90856f41d46b7be83a7ae137a7bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec0775bea4f4c95896a04a898c5853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9... training loss: 0.11973123482356851, validation loss: 0.12179198122272888,              validation_score: 0.761904776096344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6320cc57c497481d86d5dd0ca2c309bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5a6380e6634be5ac4448c78c54b204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10... training loss: 0.08758716990168278, validation loss: 0.07025497717161973,              validation_score: 0.7662337422370911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cc02239fdb4ea3b540995b478965af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee22fa62bcf4133a9d9744edb65445b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11... training loss: 0.0633208802399727, validation loss: 0.1780216848788162,              validation_score: 0.7575757503509521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56100ccdab8441c8ac03347f9a8d0558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134b68487e74697b19684e7761b2aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12... training loss: 0.0593154930554402, validation loss: 0.08551458166524147,              validation_score: 0.7575757503509521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b43aab2c17c45dba7192bd057d44a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bf1794a7c84d78a4a6d33c493371d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13... training loss: 0.04259786212328786, validation loss: 0.10138404192402958,              validation_score: 0.7705627679824829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98277433e0a14ef7bac3fe276ddbabb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eca5a0b7fd448c0b5d175c2213065b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14... training loss: 0.030895390369942807, validation loss: 0.14761297792720143,              validation_score: 0.7705627679824829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc6cf2c9ca24753b60bc81f8aeb46d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafd0b0b307949d39e7a232048da9374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15... training loss: 0.04239993996729586, validation loss: 0.14710899038376132,              validation_score: 0.7662337422370911\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, valid_losses, valid_score = train_val(model, trainloader, validloader, num_epochs,\n",
    "                                                          optimizer, loss_fn, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result: winner - simple logreg with tf-idf!!!! )))))))))))))))))))))))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befae668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e7c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f10d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd2b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503022d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8123ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ded7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1debdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01471507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a47a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6f8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a1032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46a718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f7935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c039e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36cd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
