{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7c75ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "import re\n",
    "from functools import lru_cache\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn import model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8e02f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2c8ac2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "28486497",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/intent_dataset.csv')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "819d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[а-яёЁ]+\")\n",
    "\n",
    "class_map = {\n",
    "    'open': 0,\n",
    "    'write': 1,\n",
    "    'close': 2,\n",
    "    'delete': 3,\n",
    "    'mute': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1171cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['intent'] = data['intent'].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9ebd7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7c87f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc997af",
   "metadata": {},
   "source": [
    "## logisticreg + tfidf + base preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2bf6915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, y_train, y_test = model_selection.train_test_split(data.drop('intent', axis=1), data['intent'], \n",
    "                                                                      test_size=0.1,\n",
    "                                                                      random_state=RANDOM_STATE, \n",
    "                                                                      stratify=data['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "80e6978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 784 ms, sys: 2.47 ms, total: 786 ms\n",
      "Wall time: 786 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['lemmas'] = train_df['text'].map(clean_text)\n",
    "test_df['lemmas'] = test_df['text'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b56bd5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 2.03 s, total: 3.42 s\n",
      "Wall time: 260 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98046875"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf = vec.fit_transform(train_df['lemmas'])\n",
    "\n",
    "clf = LogisticRegression(random_state=RANDOM_STATE, max_iter=10000)\n",
    "clf.fit(tfidf, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(test_df['lemmas']))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2f233141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.62 ms, sys: 593 µs, total: 5.22 ms\n",
      "Wall time: 4.32 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98046875"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = clf.predict(vec.transform(test_df['lemmas']))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "90bd1122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        55\n",
      "           1       0.96      0.96      0.96        51\n",
      "           2       0.98      1.00      0.99        51\n",
      "           3       0.98      0.98      0.98        53\n",
      "           4       0.98      0.96      0.97        46\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18e78318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 ms, sys: 0 ns, total: 1.6 ms\n",
      "Wall time: 1.67 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "407    открыть страница доставка\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df['text'].sample().map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488ab0f",
   "metadata": {},
   "source": [
    "## logisticreg + Word2Vec(FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5cbfaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=list(train_df.lemmas.str.split()), \n",
    "                          vector_size=50, window=5, workers=4, min_count=0).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9f4d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText(sentences=list(train_df.lemmas.str.split()),\n",
    "                         vector_size=50, window=5, workers=4, min_count=0).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e86d620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(df, model, embed_size=300):\n",
    "    doc_vectors = []\n",
    "    \n",
    "    for doc in tqdm(df.lemmas.str.split()):\n",
    "        res = np.zeros(embed_size)\n",
    "        cnt = 0\n",
    "        for word in doc:\n",
    "            res += model[word]\n",
    "            cnt += 1\n",
    "        if cnt != 0:\n",
    "            res /= cnt\n",
    "        \n",
    "        doc_vectors.append(res)\n",
    "    \n",
    "    return np.array(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2431da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_w2v(df, model, embed_size=300):\n",
    "    doc_vectors = []\n",
    "    \n",
    "    for doc in tqdm(df.lemmas.str.split()):\n",
    "        res = np.zeros(embed_size)\n",
    "        cnt = 0\n",
    "        for word in doc:\n",
    "            if model.__contains__(word):\n",
    "                res += model[word]\n",
    "                cnt += 1\n",
    "        if cnt != 0:\n",
    "            res /= cnt\n",
    "        doc_vectors.append(res)\n",
    "        \n",
    "    return np.array(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e9457e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c1d70a6aa64023872875e10fbf2d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f687d6335f4e088bb72283552f24d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 ms, sys: 1.82 ms, total: 124 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#word2vec\n",
    "train_w2v = get_embeddings_w2v(train_df, word2vec_model, 50)\n",
    "test_w2v = get_embeddings_w2v(test_df, word2vec_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14b0d8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640625"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pd.DataFrame(train_w2v), y_train)\n",
    "\n",
    "pred = clf.predict(pd.DataFrame(test_w2v))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "46f55bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4916f4c5f348459cbb5fa95573ab1c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58b16d0b8594073a7e81832d473201d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.6 ms, sys: 12.3 ms, total: 109 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasttext\n",
    "train_fasttext = get_embeddings(train_df, fasttext_model, 50)\n",
    "test_fasttext = get_embeddings(test_df, fasttext_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ab2ab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34375"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pd.DataFrame(train_fasttext), y_train)\n",
    "\n",
    "pred = clf.predict(pd.DataFrame(test_fasttext))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9e3fa",
   "metadata": {},
   "source": [
    "## logisticreg + Word2Vec(FastText) + TF-IDF(CountVec) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3d7c6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tfidf(df, model, embed_size=50):\n",
    "    doc_vectors = []\n",
    "    \n",
    "    for doc in tqdm(df.lemmas.str.split()):\n",
    "        res = np.zeros(embed_size)\n",
    "        cnt = 0\n",
    "        for word in doc:\n",
    "            if model.__contains__(word):\n",
    "                res += tf_idf_voc[word] * model[word]\n",
    "                cnt += 1\n",
    "        if cnt != 0:\n",
    "            res /= cnt\n",
    "        doc_vectors.append(res)\n",
    "    \n",
    "    return doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f4a1a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf = vec.fit_transform(train_df['lemmas'])\n",
    "\n",
    "tf_idf_voc = {word: vec.idf_[i] for word, i in vec.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7a11b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a02f1e7b23f433e8ff0ead7a4c5a4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299d2ca031c34d16845bc5383c3e11db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88.1 ms, sys: 7.97 ms, total: 96.1 ms\n",
      "Wall time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasttext\n",
    "train_w2v = w2v_tfidf(train_df, word2vec_model, 50)\n",
    "test_w2v = w2v_tfidf(test_df, word2vec_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "466e4ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80078125"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pd.DataFrame(train_w2v), y_train)\n",
    "\n",
    "pred = clf.predict(pd.DataFrame(test_w2v))\n",
    "metrics.accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a6219df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестить преобученные не буду\\ нет смысла."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7c916",
   "metadata": {},
   "source": [
    "## conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6985f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
